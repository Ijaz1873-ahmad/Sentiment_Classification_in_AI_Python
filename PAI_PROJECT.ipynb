{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d863b8a",
   "metadata": {},
   "source": [
    "## Name: Ijaz Ahmad\n",
    "## ID: I19-1873"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b590924c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "17dcfe71",
   "metadata": {},
   "source": [
    "# Text Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ddb08f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53ee6a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d766a894",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f8c081f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>image_name</th>\n",
       "      <th>text_ocr</th>\n",
       "      <th>text_corrected</th>\n",
       "      <th>overall_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>image_1.jpg</td>\n",
       "      <td>LOOK THERE MY FRIEND LIGHTYEAR NOW ALL SOHALIK...</td>\n",
       "      <td>LOOK THERE MY FRIEND LIGHTYEAR NOW ALL SOHALIK...</td>\n",
       "      <td>very_positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>image_2.jpeg</td>\n",
       "      <td>The best of #10 YearChallenge! Completed in le...</td>\n",
       "      <td>The best of #10 YearChallenge! Completed in le...</td>\n",
       "      <td>very_positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>image_3.JPG</td>\n",
       "      <td>Sam Thorne @Strippin ( Follow Follow Saw every...</td>\n",
       "      <td>Sam Thorne @Strippin ( Follow Follow Saw every...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>image_4.png</td>\n",
       "      <td>10 Year Challenge - Sweet Dee Edition</td>\n",
       "      <td>10 Year Challenge - Sweet Dee Edition</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>image_5.png</td>\n",
       "      <td>10 YEAR CHALLENGE WITH NO FILTER 47 Hilarious ...</td>\n",
       "      <td>10 YEAR CHALLENGE WITH NO FILTER 47 Hilarious ...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0    image_name  \\\n",
       "0           0   image_1.jpg   \n",
       "1           1  image_2.jpeg   \n",
       "2           2   image_3.JPG   \n",
       "3           3   image_4.png   \n",
       "4           4   image_5.png   \n",
       "\n",
       "                                            text_ocr  \\\n",
       "0  LOOK THERE MY FRIEND LIGHTYEAR NOW ALL SOHALIK...   \n",
       "1  The best of #10 YearChallenge! Completed in le...   \n",
       "2  Sam Thorne @Strippin ( Follow Follow Saw every...   \n",
       "3              10 Year Challenge - Sweet Dee Edition   \n",
       "4  10 YEAR CHALLENGE WITH NO FILTER 47 Hilarious ...   \n",
       "\n",
       "                                      text_corrected overall_sentiment  \n",
       "0  LOOK THERE MY FRIEND LIGHTYEAR NOW ALL SOHALIK...     very_positive  \n",
       "1  The best of #10 YearChallenge! Completed in le...     very_positive  \n",
       "2  Sam Thorne @Strippin ( Follow Follow Saw every...          positive  \n",
       "3              10 Year Challenge - Sweet Dee Edition          positive  \n",
       "4  10 YEAR CHALLENGE WITH NO FILTER 47 Hilarious ...           neutral  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"labels.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4c3db3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data[['text_corrected', 'overall_sentiment']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5583b83a",
   "metadata": {},
   "source": [
    "### mapping each sentiment with respective value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a7b9797",
   "metadata": {},
   "outputs": [],
   "source": [
    "order={\"very_positive\":1,\"positive\":1,\"neutral\":0,\"negative\":-1,\"very_negative\":-1}\n",
    "df['overall_sentiment_label'] = df['overall_sentiment'].map(order)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6134f28",
   "metadata": {},
   "source": [
    "### spliting the dataset into two parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce6ee560",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['text_corrected']\n",
    "y = df['overall_sentiment_label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e17f59e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6992,), (6992,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02be748a",
   "metadata": {},
   "source": [
    "### cleaning Training DataSet 'X'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b91f612b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_Data = []\n",
    "stem = WordNetLemmatizer()\n",
    "stopwords_nltk = set(stopwords.words(\"english\"))\n",
    "\n",
    "for sen in range(len(X)):\n",
    "    text = str(X[sen])\n",
    "    words = text.split(\" \")\n",
    "    alpha = [word for word in words if word.isalpha()]\n",
    "    lower = [word.lower() for word in alpha]\n",
    "    cleanedwords = [word for word in lower if word not in stopwords_nltk]\n",
    "    stemWords = [stem.lemmatize(word) for word in cleanedwords]\n",
    "    cleanText = ' '.join(stemWords)\n",
    "    cleaned_Data.append(cleanText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f2cfee69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6992"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cleaned_Data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c77c7b",
   "metadata": {},
   "source": [
    "### vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ab7125",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "66377352",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidfconverter = TfidfVectorizer(smooth_idf = False)\n",
    "X = tfidfconverter.fit_transform(cleaned_Data).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c2d1fb",
   "metadata": {},
   "source": [
    "### divide the dataset into training and testing  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5e2d0a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=101)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "791eb0e9",
   "metadata": {},
   "source": [
    "### MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "92aebe9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score:  0.3123758950513804\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.10      0.07      0.08       131\n",
      "           0       0.29      0.19      0.23       462\n",
      "           1       0.56      0.70      0.62       806\n",
      "\n",
      "    accuracy                           0.47      1399\n",
      "   macro avg       0.32      0.32      0.31      1399\n",
      "weighted avg       0.43      0.47      0.44      1399\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "model1 = MultinomialNB(alpha = .01)\n",
    "model1.fit(X_train, y_train)\n",
    "y_predict = model1.predict(X_test)\n",
    "print(\"F1 Score: \",f1_score(y_test, y_predict,average='macro'))\n",
    "print(\"Classification Report: \\n\", classification_report(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35371333",
   "metadata": {},
   "source": [
    "# BaggingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f055c258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score:  0.3140337821830959\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.09      0.02      0.03       131\n",
      "           0       0.32      0.23      0.27       462\n",
      "           1       0.57      0.75      0.65       806\n",
      "\n",
      "    accuracy                           0.51      1399\n",
      "   macro avg       0.33      0.33      0.31      1399\n",
      "weighted avg       0.45      0.51      0.46      1399\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "model2 = BaggingClassifier()\n",
    "model2.fit(X_train, y_train)\n",
    "pred = model2.predict(X_test)\n",
    "print(\"F1 Score: \",f1_score(y_test, pred,average='macro'))\n",
    "print(\"Classification Report: \\n\", classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f7f03bd",
   "metadata": {},
   "source": [
    "# ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "feec5791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score:  0.3181382467973178\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.18      0.03      0.05       131\n",
      "           0       0.32      0.18      0.23       462\n",
      "           1       0.58      0.81      0.67       806\n",
      "\n",
      "    accuracy                           0.53      1399\n",
      "   macro avg       0.36      0.34      0.32      1399\n",
      "weighted avg       0.46      0.53      0.47      1399\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "model3 =  ExtraTreesClassifier(random_state=70)\n",
    "model3.fit(X_train, y_train)\n",
    "pred3 = model3.predict(X_test)\n",
    "print(\"F1 Score: \",f1_score(y_test, pred3,average='macro'))\n",
    "print(\"Classification Report: \\n\", classification_report(y_test, pred3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5036bc1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import VotingClassifier\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.naive_bayes import GaussianNB\n",
    "# from sklearn.svm import SVC\n",
    "\n",
    "# clf1 = LogisticRegression(random_state=42)\n",
    "# clf2 = RandomForestClassifier(random_state=42)\n",
    "# clf3 = GaussianNB()\n",
    "# clf4 = SVC(probability=True, random_state=42)\n",
    "\n",
    "# eclf = VotingClassifier(estimators=[('LR', clf1), ('RF', clf2), ('GNB', clf3), ('SVC', clf4)],\n",
    "#                         voting='soft', weights=[1,2,1,1])\n",
    "\n",
    "# eclf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5173f67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# p = eclf.predict(X_test)\n",
    "# print(\"F1 Score: \",f1_score(y_test, p,average='macro'))\n",
    "# print(\"Classification Report: \\n\", classification_report(y_test, p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ad9ab5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of evaluating a stacking ensemble for classification\n",
    "# from numpy import mean\n",
    "# from numpy import std\n",
    "# from sklearn.model_selection import cross_val_score\n",
    "# from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "# from sklearn.ensemble import StackingClassifier\n",
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# models = [('knn', KNeighborsClassifier()), ('tree', DecisionTreeClassifier())]\n",
    "# model = StackingClassifier(models, final_estimator=LogisticRegression(), cv=3)\n",
    "# cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# n_scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "# # report ensemble performance\n",
    "# print('Mean Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8673a3b6",
   "metadata": {},
   "source": [
    "# Voting between Text model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7a75dec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "682fe2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "clfv1 = VotingClassifier(estimators=[('NB', model1),('BC', model2),('AB', model3)], voting='hard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "db797299",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score:  0.31998213612248705\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.15      0.05      0.07       131\n",
      "           0       0.32      0.16      0.22       462\n",
      "           1       0.58      0.80      0.67       806\n",
      "\n",
      "    accuracy                           0.52      1399\n",
      "   macro avg       0.35      0.34      0.32      1399\n",
      "weighted avg       0.45      0.52      0.47      1399\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clfv1.fit(X_train, y_train)\n",
    "clfv1_Predictions = clfv1.predict(X_test)\n",
    "\n",
    "print(\"F1 Score: \",f1_score(y_test, clfv1_Predictions, average='macro'))\n",
    "print(\"Classification Report: \\n\", classification_report(y_test, clfv1_Predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "270b013e",
   "metadata": {},
   "source": [
    "# Images data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d3a2610b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from skimage.io import imread, imshow\n",
    "from skimage import filters\n",
    "from skimage import feature\n",
    "from PIL import Image\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1dfb06f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from skimage.io import imread, imshow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1c373f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score, classification_report \n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "43318c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path of both main and resize dir\n",
    "path = r'.\\images'\n",
    "save_path = r'.\\resized_images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9f21b7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if dir exsit first delete it then make a new one\n",
    "# this is for multiple runs\n",
    "import shutil\n",
    "if os.path.exists(save_path):\n",
    "    shutil.rmtree(save_path)\n",
    "os.mkdir(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2129de93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>image_name</th>\n",
       "      <th>text_ocr</th>\n",
       "      <th>text_corrected</th>\n",
       "      <th>overall_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>image_1.jpg</td>\n",
       "      <td>LOOK THERE MY FRIEND LIGHTYEAR NOW ALL SOHALIK...</td>\n",
       "      <td>LOOK THERE MY FRIEND LIGHTYEAR NOW ALL SOHALIK...</td>\n",
       "      <td>very_positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>image_2.jpeg</td>\n",
       "      <td>The best of #10 YearChallenge! Completed in le...</td>\n",
       "      <td>The best of #10 YearChallenge! Completed in le...</td>\n",
       "      <td>very_positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>image_3.JPG</td>\n",
       "      <td>Sam Thorne @Strippin ( Follow Follow Saw every...</td>\n",
       "      <td>Sam Thorne @Strippin ( Follow Follow Saw every...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0    image_name  \\\n",
       "0           0   image_1.jpg   \n",
       "1           1  image_2.jpeg   \n",
       "2           2   image_3.JPG   \n",
       "\n",
       "                                            text_ocr  \\\n",
       "0  LOOK THERE MY FRIEND LIGHTYEAR NOW ALL SOHALIK...   \n",
       "1  The best of #10 YearChallenge! Completed in le...   \n",
       "2  Sam Thorne @Strippin ( Follow Follow Saw every...   \n",
       "\n",
       "                                      text_corrected overall_sentiment  \n",
       "0  LOOK THERE MY FRIEND LIGHTYEAR NOW ALL SOHALIK...     very_positive  \n",
       "1  The best of #10 YearChallenge! Completed in le...     very_positive  \n",
       "2  Sam Thorne @Strippin ( Follow Follow Saw every...          positive  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import the dataset again\n",
    "df = pd.read_csv('labels.csv')\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d7b5086e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sperate the image col\n",
    "names = df['image_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7d1b0a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# map each setiment from 5 to 1\n",
    "order={\"very_positive\":1,\"positive\":1,\"neutral\":0,\"negative\":-1,\"very_negative\":-1}\n",
    "df['overall_sentiment_label'] = df['overall_sentiment'].map(order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6654a519",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>image_name</th>\n",
       "      <th>text_ocr</th>\n",
       "      <th>text_corrected</th>\n",
       "      <th>overall_sentiment</th>\n",
       "      <th>overall_sentiment_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>image_1.jpg</td>\n",
       "      <td>LOOK THERE MY FRIEND LIGHTYEAR NOW ALL SOHALIK...</td>\n",
       "      <td>LOOK THERE MY FRIEND LIGHTYEAR NOW ALL SOHALIK...</td>\n",
       "      <td>very_positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>image_2.jpeg</td>\n",
       "      <td>The best of #10 YearChallenge! Completed in le...</td>\n",
       "      <td>The best of #10 YearChallenge! Completed in le...</td>\n",
       "      <td>very_positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>image_3.JPG</td>\n",
       "      <td>Sam Thorne @Strippin ( Follow Follow Saw every...</td>\n",
       "      <td>Sam Thorne @Strippin ( Follow Follow Saw every...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0    image_name  \\\n",
       "0           0   image_1.jpg   \n",
       "1           1  image_2.jpeg   \n",
       "2           2   image_3.JPG   \n",
       "\n",
       "                                            text_ocr  \\\n",
       "0  LOOK THERE MY FRIEND LIGHTYEAR NOW ALL SOHALIK...   \n",
       "1  The best of #10 YearChallenge! Completed in le...   \n",
       "2  Sam Thorne @Strippin ( Follow Follow Saw every...   \n",
       "\n",
       "                                      text_corrected overall_sentiment  \\\n",
       "0  LOOK THERE MY FRIEND LIGHTYEAR NOW ALL SOHALIK...     very_positive   \n",
       "1  The best of #10 YearChallenge! Completed in le...     very_positive   \n",
       "2  Sam Thorne @Strippin ( Follow Follow Saw every...          positive   \n",
       "\n",
       "   overall_sentiment_label  \n",
       "0                        1  \n",
       "1                        1  \n",
       "2                        1  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bef25760",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Truncated image\n",
      ".\\images\\image_5119.png\n",
      "Successfully done!\n"
     ]
    }
   ],
   "source": [
    "# loop over all images to resize them and save them to new-path \"resize_images\"\n",
    "for i in range(len(names)):\n",
    "    try:\n",
    "        imgpath = path + \"\\\\\" + names[i]\n",
    "        img = Image.open(imgpath)\n",
    "        if img.mode != 'RGB':\n",
    "            img = img.convert('RGB')\n",
    "\n",
    "        img2 = img.resize((30,30))\n",
    "        new_name = save_path + \"\\\\\" + names[i]        \n",
    "        img2.save(new_name)\n",
    "#         fd, hog_image = hog(img2, orientations=9, pixels_per_cell=(8, 8), \n",
    "#                     cells_per_block=(2, 2), visualize=True, multichannel=True)\n",
    "#         features.append(fd)\n",
    "    \n",
    "    except:        \n",
    "        print('Truncated image')\n",
    "        print(imgpath)\n",
    "        #features.append(np.nan)\n",
    "print(\"Successfully done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "01959b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function will return the soble features\n",
    "# of each image\n",
    "def get_sobel_features(image):\n",
    "    ed_sobel = filters.sobel(image)\n",
    "    return ed_sobel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a2324eaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\\resized_images\\image_5119.png\n",
      "Successfully done!\n"
     ]
    }
   ],
   "source": [
    "sobel_features=[] # list to store sobel-featurs\n",
    "path = r'.\\resized_images'\n",
    "\n",
    "for i in range(len(names)-1):\n",
    "    imgpath = imgpath = path + \"\\\\\" + names[i]\n",
    "    if i == 5118:\n",
    "        print(imgpath)\n",
    "        sobel_features.append(np.nan)\n",
    "        continue\n",
    "    \n",
    "    image1 = imread(imgpath, as_gray=True)     \n",
    "    features = np.array(get_sobel_features(image1))\n",
    "    sobel_features.append(features)\n",
    "    \n",
    "print(\"Successfully done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f8ac4e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(5118)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "68600b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Features'] = sobel_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ddaaea46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>image_name</th>\n",
       "      <th>text_ocr</th>\n",
       "      <th>text_corrected</th>\n",
       "      <th>overall_sentiment</th>\n",
       "      <th>overall_sentiment_label</th>\n",
       "      <th>Features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>image_1.jpg</td>\n",
       "      <td>LOOK THERE MY FRIEND LIGHTYEAR NOW ALL SOHALIK...</td>\n",
       "      <td>LOOK THERE MY FRIEND LIGHTYEAR NOW ALL SOHALIK...</td>\n",
       "      <td>very_positive</td>\n",
       "      <td>1</td>\n",
       "      <td>[[0.01462766841720581, 0.042760404753765816, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>image_2.jpeg</td>\n",
       "      <td>The best of #10 YearChallenge! Completed in le...</td>\n",
       "      <td>The best of #10 YearChallenge! Completed in le...</td>\n",
       "      <td>very_positive</td>\n",
       "      <td>1</td>\n",
       "      <td>[[0.028889749338637253, 0.11560853377964683, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>image_3.JPG</td>\n",
       "      <td>Sam Thorne @Strippin ( Follow Follow Saw every...</td>\n",
       "      <td>Sam Thorne @Strippin ( Follow Follow Saw every...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "      <td>[[0.04392511466219837, 0.2409647798594005, 0.6...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0    image_name  \\\n",
       "0           0   image_1.jpg   \n",
       "1           1  image_2.jpeg   \n",
       "2           2   image_3.JPG   \n",
       "\n",
       "                                            text_ocr  \\\n",
       "0  LOOK THERE MY FRIEND LIGHTYEAR NOW ALL SOHALIK...   \n",
       "1  The best of #10 YearChallenge! Completed in le...   \n",
       "2  Sam Thorne @Strippin ( Follow Follow Saw every...   \n",
       "\n",
       "                                      text_corrected overall_sentiment  \\\n",
       "0  LOOK THERE MY FRIEND LIGHTYEAR NOW ALL SOHALIK...     very_positive   \n",
       "1  The best of #10 YearChallenge! Completed in le...     very_positive   \n",
       "2  Sam Thorne @Strippin ( Follow Follow Saw every...          positive   \n",
       "\n",
       "   overall_sentiment_label                                           Features  \n",
       "0                        1  [[0.01462766841720581, 0.042760404753765816, 0...  \n",
       "1                        1  [[0.028889749338637253, 0.11560853377964683, 0...  \n",
       "2                        1  [[0.04392511466219837, 0.2409647798594005, 0.6...  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e6209b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df[['Features', 'overall_sentiment_label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0efd5e1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 6991 entries, 0 to 6991\n",
      "Data columns (total 2 columns):\n",
      " #   Column                   Non-Null Count  Dtype \n",
      "---  ------                   --------------  ----- \n",
      " 0   Features                 6990 non-null   object\n",
      " 1   overall_sentiment_label  6991 non-null   int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 163.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "13fb94ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 6990 entries, 0 to 6991\n",
      "Data columns (total 2 columns):\n",
      " #   Column                   Non-Null Count  Dtype \n",
      "---  ------                   --------------  ----- \n",
      " 0   Features                 6990 non-null   object\n",
      " 1   overall_sentiment_label  6990 non-null   int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 163.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df1.dropna(axis=0, inplace=True)\n",
    "df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "249a350f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully done!\n"
     ]
    }
   ],
   "source": [
    "fd = df1['Features']\n",
    "dum = pd.DataFrame() # make a dummy DataFrame to reshize the features\n",
    "for i in range(len(fd)):\n",
    "    temp = pd.DataFrame(fd.iloc[i].reshape(1,900))\n",
    "    dum = dum.append(temp)\n",
    "print(\"Successfully done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "07ffe1a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>890</th>\n",
       "      <th>891</th>\n",
       "      <th>892</th>\n",
       "      <th>893</th>\n",
       "      <th>894</th>\n",
       "      <th>895</th>\n",
       "      <th>896</th>\n",
       "      <th>897</th>\n",
       "      <th>898</th>\n",
       "      <th>899</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.014628</td>\n",
       "      <td>0.042760</td>\n",
       "      <td>0.030482</td>\n",
       "      <td>0.002168</td>\n",
       "      <td>0.017837</td>\n",
       "      <td>0.055762</td>\n",
       "      <td>0.160481</td>\n",
       "      <td>0.197884</td>\n",
       "      <td>0.203825</td>\n",
       "      <td>0.172458</td>\n",
       "      <td>...</td>\n",
       "      <td>0.090470</td>\n",
       "      <td>0.077351</td>\n",
       "      <td>0.097626</td>\n",
       "      <td>0.118565</td>\n",
       "      <td>0.107398</td>\n",
       "      <td>0.110816</td>\n",
       "      <td>0.125360</td>\n",
       "      <td>0.119153</td>\n",
       "      <td>0.087213</td>\n",
       "      <td>0.048821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.028890</td>\n",
       "      <td>0.115609</td>\n",
       "      <td>0.094512</td>\n",
       "      <td>0.026434</td>\n",
       "      <td>0.016477</td>\n",
       "      <td>0.013112</td>\n",
       "      <td>0.062954</td>\n",
       "      <td>0.051856</td>\n",
       "      <td>0.036410</td>\n",
       "      <td>0.006343</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006413</td>\n",
       "      <td>0.014226</td>\n",
       "      <td>0.004431</td>\n",
       "      <td>0.008340</td>\n",
       "      <td>0.003570</td>\n",
       "      <td>0.000794</td>\n",
       "      <td>0.008730</td>\n",
       "      <td>0.010398</td>\n",
       "      <td>0.005689</td>\n",
       "      <td>0.010577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.043925</td>\n",
       "      <td>0.240965</td>\n",
       "      <td>0.618214</td>\n",
       "      <td>0.321785</td>\n",
       "      <td>0.129623</td>\n",
       "      <td>0.143364</td>\n",
       "      <td>0.105365</td>\n",
       "      <td>0.076359</td>\n",
       "      <td>0.085911</td>\n",
       "      <td>0.077154</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011979</td>\n",
       "      <td>0.031001</td>\n",
       "      <td>0.020096</td>\n",
       "      <td>0.005583</td>\n",
       "      <td>0.003745</td>\n",
       "      <td>0.011316</td>\n",
       "      <td>0.124373</td>\n",
       "      <td>0.373182</td>\n",
       "      <td>0.244877</td>\n",
       "      <td>0.004716</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 900 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0  0.014628  0.042760  0.030482  0.002168  0.017837  0.055762  0.160481   \n",
       "0  0.028890  0.115609  0.094512  0.026434  0.016477  0.013112  0.062954   \n",
       "0  0.043925  0.240965  0.618214  0.321785  0.129623  0.143364  0.105365   \n",
       "\n",
       "        7         8         9    ...       890       891       892       893  \\\n",
       "0  0.197884  0.203825  0.172458  ...  0.090470  0.077351  0.097626  0.118565   \n",
       "0  0.051856  0.036410  0.006343  ...  0.006413  0.014226  0.004431  0.008340   \n",
       "0  0.076359  0.085911  0.077154  ...  0.011979  0.031001  0.020096  0.005583   \n",
       "\n",
       "        894       895       896       897       898       899  \n",
       "0  0.107398  0.110816  0.125360  0.119153  0.087213  0.048821  \n",
       "0  0.003570  0.000794  0.008730  0.010398  0.005689  0.010577  \n",
       "0  0.003745  0.011316  0.124373  0.373182  0.244877  0.004716  \n",
       "\n",
       "[3 rows x 900 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dum.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9f68ee24",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dum\n",
    "y = df1['overall_sentiment_label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9d81c1a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6990, 900), (6990,))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "70793418",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X, y, test_size=0.2, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0942ca1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score:  0.32103192095289423\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.05      0.01      0.01       125\n",
      "           0       0.36      0.20      0.25       452\n",
      "           1       0.60      0.83      0.70       821\n",
      "\n",
      "    accuracy                           0.55      1398\n",
      "   macro avg       0.34      0.34      0.32      1398\n",
      "weighted avg       0.47      0.55      0.49      1398\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf1 = LogisticRegression()\n",
    "clf1.fit(X_train2, y_train2)\n",
    "pred2 = clf1.predict(X_test2)\n",
    "print(\"F1 Score: \",f1_score(y_test2, pred2, average='macro'))\n",
    "print(\"Classification Report: \\n\", classification_report(y_test2, pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b414c74b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score:  0.3441731607712215\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.09      0.10      0.10       125\n",
      "           0       0.34      0.34      0.34       452\n",
      "           1       0.60      0.59      0.60       821\n",
      "\n",
      "    accuracy                           0.46      1398\n",
      "   macro avg       0.34      0.34      0.34      1398\n",
      "weighted avg       0.47      0.46      0.47      1398\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf2 = DecisionTreeClassifier()\n",
    "clf2.fit(X_train2, y_train2)\n",
    "pred3 = clf2.predict(X_test2)\n",
    "print(\"F1 Score: \",f1_score(y_test2, pred3, average='macro'))\n",
    "print(\"Classification Report: \\n\", classification_report(y_test2, pred3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1a4bde56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score:  0.3333030585865742\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.08      0.03      0.04       125\n",
      "           0       0.35      0.25      0.29       452\n",
      "           1       0.60      0.75      0.67       821\n",
      "\n",
      "    accuracy                           0.52      1398\n",
      "   macro avg       0.34      0.34      0.33      1398\n",
      "weighted avg       0.47      0.52      0.49      1398\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "clf = KNeighborsClassifier()\n",
    "clf.fit(X_train2, y_train2)\n",
    "pred = clf.predict(X_test2)\n",
    "print(\"F1 Score: \",f1_score(y_test2, pred, average='macro'))\n",
    "print(\"Classification Report: \\n\", classification_report(y_test2, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ee8d76a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4b8875ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "clfv2 = VotingClassifier(estimators=[('RF', clf1),('DT', clf2),('KNN', clf)], voting='hard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cf363b9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score:  0.33247070044277155\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.09      0.05      0.06       125\n",
      "           0       0.38      0.17      0.23       452\n",
      "           1       0.60      0.83      0.70       821\n",
      "\n",
      "    accuracy                           0.55      1398\n",
      "   macro avg       0.36      0.35      0.33      1398\n",
      "weighted avg       0.49      0.55      0.49      1398\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clfv2.fit(X_train2, y_train2)\n",
    "clfv2_Predictions = clfv2.predict(X_test2)\n",
    "\n",
    "print(\"F1 Score: \",f1_score(y_test2, clfv2_Predictions, average='macro'))\n",
    "print(\"Classification Report: \\n\", classification_report(y_test2, clfv2_Predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b69e36f",
   "metadata": {},
   "source": [
    "# Now Voting between Image final and Text final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "879c3e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5e61ea34",
   "metadata": {},
   "outputs": [],
   "source": [
    "final = VotingClassifier(estimators=[('IM', clfv2),('TX', clfv1)], voting='hard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13290c4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "386498e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score:  0.33498193371516566\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.10      0.06      0.07       125\n",
      "           0       0.37      0.19      0.25       452\n",
      "           1       0.60      0.80      0.69       821\n",
      "\n",
      "    accuracy                           0.54      1398\n",
      "   macro avg       0.36      0.35      0.33      1398\n",
      "weighted avg       0.48      0.54      0.49      1398\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final.fit(X_train2, y_train2)\n",
    "final_Predictions = final.predict(X_test2)\n",
    "\n",
    "print(\"F1 Score: \",f1_score(y_test2, final_Predictions, average='macro'))\n",
    "print(\"Classification Report: \\n\", classification_report(y_test2, final_Predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b312a7a",
   "metadata": {},
   "source": [
    "## save pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "099336d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "Pkl_Filename = \"final_result.pkl\"  \n",
    "\n",
    "with open(Pkl_Filename, 'wb') as file:  \n",
    "    pickle.dump(final, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666b3eff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
